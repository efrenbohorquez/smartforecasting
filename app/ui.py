import gradio as gr
from app.data import get_bodegas, load_global_stats
from app.models import predict_bodega, DF_RESULTS
from app.plots import plot_forecast_interactive, plot_mae_distribution, get_hyperparameter_stats

# --- INTERFAZ GRADIO ---

def actualizar_bodegas(producto):
    return gr.Dropdown(choices=get_bodegas(producto), value=None)

def ejecutar_demo(producto, bodega):
    df_plot, metrics, stats, mae = predict_bodega(producto, bodega)
    if df_plot is None:
        return None, metrics, None # metrics contiene el error
    
    fig = plot_forecast_interactive(df_plot, mae)
    return fig, metrics, stats

# Cargar stats globales para la pesta√±a 2
STATS = load_global_stats()

def create_demo():
    with gr.Blocks(title="Sistema de Predicci√≥n de Demanda LSTM", theme=gr.themes.Soft()) as demo:
        gr.Markdown("""
        # üß† Sistema de Predicci√≥n de Demanda con LSTM
        **Proyecto de Maestr√≠a en Deep Learning**
        """)
        
        with gr.Tabs():
            # TAB 1: AN√ÅLISIS INDIVIDUAL
            with gr.Tab("üìä An√°lisis Individual"):
                with gr.Row():
                    with gr.Column(scale=1):
                        gr.Markdown("### Configuraci√≥n")
                        in_prod = gr.Dropdown(choices=["P9933", "P2417"], label="Producto", value="P9933")
                        in_bodega = gr.Dropdown(choices=get_bodegas("P9933"), label="Bodega")
                        btn_pred = gr.Button("Generar Predicci√≥n", variant="primary")
                        
                        gr.Markdown("---")
                        out_metrics = gr.Markdown("Seleccione una bodega y presione 'Generar Predicci√≥n'")
                        out_stats = gr.Markdown("")
                        
                    with gr.Column(scale=2):
                        out_plot = gr.Plot(label="Gr√°fica de Pron√≥stico")
                
                in_prod.change(fn=actualizar_bodegas, inputs=in_prod, outputs=in_bodega)
                btn_pred.click(fn=ejecutar_demo, inputs=[in_prod, in_bodega], outputs=[out_plot, out_metrics, out_stats])

            # TAB 2: AN√ÅLISIS GLOBAL
            with gr.Tab("üåç An√°lisis Global"):
                if STATS:
                    gr.Markdown("### Resumen de Rendimiento del Modelo")
                    with gr.Row():
                        with gr.Column():
                            gr.Number(label="Total Modelos", value=STATS['global']['total_modelos'], interactive=False)
                            gr.Number(label="Precisi√≥n Promedio (MAE)", value=STATS['producto_A']['mae_promedio'], interactive=False)
                        with gr.Column():
                            gr.Number(label="Demanda Total Predicha (Mar 25)", value=STATS['global']['demanda_total_predicha'], interactive=False)
                            gr.Number(label="Registros Analizados", value=STATS['global']['registros_analizados'], interactive=False)
                    
                    gr.Markdown("---")
                    gr.Markdown("### üìä An√°lisis de Errores y Arquitectura")
                    
                    with gr.Row():
                        with gr.Column(scale=2):
                            gr.Markdown("#### Distribuci√≥n de Errores (MAE)")
                            gr.Plot(value=plot_mae_distribution(DF_RESULTS), label="Distribuci√≥n MAE")
                        
                        with gr.Column(scale=1):
                            gr.Markdown("#### Hiperpar√°metros √ìptimos")
                            fig_u, fig_lr = get_hyperparameter_stats(DF_RESULTS)
                            gr.Plot(value=fig_u, label="Unidades LSTM")
                            gr.Plot(value=fig_lr, label="Learning Rates")

                    gr.Markdown("---")
                    gr.Markdown("### Detalles por Producto")
                    with gr.Row():
                        with gr.Column():
                            gr.Markdown("#### Producto P9933 (A)")
                            gr.JSON(STATS['producto_A'])
                        with gr.Column():
                            gr.Markdown("#### Producto P2417 (B)")
                            gr.JSON(STATS['producto_B'])
                else:
                    gr.Markdown("‚ö†Ô∏è No se encontr√≥ el archivo `estadisticas_globales.json`. Ejecute primero el script de an√°lisis completo.")

            # TAB 3: DETALLES T√âCNICOS
            with gr.Tab("üõ†Ô∏è Detalles T√©cnicos"):
                gr.Markdown("## üèóÔ∏è Arquitectura y Proceso de Entrenamiento")
                
                with gr.Row():
                    with gr.Column():
                        gr.Markdown("""
                        ### 1. Topolog√≠a de la Red (LSTM)
                        El modelo utiliza una arquitectura **Long Short-Term Memory (LSTM)**, dise√±ada espec√≠ficamente para problemas de series temporales.
                        
                        - **Input Layer:** Recibe una matriz de `(6, 1)`, representando 6 meses de historia con 1 caracter√≠stica (demanda).
                        - **LSTM Layer:** Extrae patrones temporales complejos (tendencias, estacionalidad). El n√∫mero de unidades var√≠a entre 32 y 128 seg√∫n la optimizaci√≥n.
                        - **Dense Layer:** Una capa completamente conectada que condensa la informaci√≥n en un √∫nico valor de predicci√≥n.
                        - **Output:** Un escalar que representa la demanda estimada para el mes `t+1`.
                        """)
                        gr.Image("04_DOCUMENTACION/assets/network_topology.png", label="Topolog√≠a de la Red", show_label=True)
                    
                    with gr.Column():
                        gr.Markdown("""
                        ### 2. Pipeline de Entrenamiento
                        El proceso de construcci√≥n del modelo sigue un flujo riguroso para asegurar la robustez:
                        
                        1. **Preprocesamiento:** Normalizaci√≥n MinMax (0-1) y creaci√≥n de ventanas deslizantes.
                        2. **Split:** Divisi√≥n temporal en Train (Entrenamiento), Val (Validaci√≥n) y Test (Prueba).
                        3. **Optimizaci√≥n (Keras Tuner):** B√∫squeda autom√°tica de los mejores hiperpar√°metros (Learning Rate, Unidades LSTM).
                        4. **Entrenamiento:** Uso de `EarlyStopping` para evitar sobreajuste (overfitting).
                        5. **Evaluaci√≥n:** C√°lculo del MAE (Error Absoluto Medio) en el conjunto de prueba.
                        """)
                        gr.Image("04_DOCUMENTACION/assets/training_pipeline.png", label="Flujo de Entrenamiento", show_label=True)
                
                gr.Markdown("---")
                gr.Markdown("""
                ### ‚öôÔ∏è Configuraci√≥n de Hiperpar√°metros
                
                | Par√°metro | Configuraci√≥n | Descripci√≥n |
                |-----------|---------------|-------------|
                | **Optimizador** | Adam | Algoritmo de optimizaci√≥n adaptativo. |
                | **Loss Function** | MSE (Mean Squared Error) | Funci√≥n de p√©rdida para regresi√≥n, penaliza grandes errores. |
                | **M√©trica** | MAE (Mean Absolute Error) | M√©trica interpretable (unidades de producto). |
                | **Ventana** | 6 Meses | Cantidad de historia usada para cada predicci√≥n. |
                | **Epochs** | 100 (con Early Stopping) | M√°ximo de iteraciones de entrenamiento. |
                """)

            # TAB 4: EXPLICACI√ìN DID√ÅCTICA
            with gr.Tab("üéì Explicaci√≥n Did√°ctica"):
                gr.Markdown("## üß† ¬øC√≥mo funciona la Inteligencia Artificial?")
                
                with gr.Row():
                    with gr.Column():
                        gr.Markdown("""
                        ### 1. La Ventana Deslizante (Sliding Window)
                        
                        Para predecir el futuro, la IA necesita "mirar" el pasado. Usamos una t√©cnica llamada **Ventana Deslizante**.
                        
                        Imagina que tienes una ventana que solo te deja ver 6 meses a la vez.
                        - **Entrada (X):** La IA observa los meses 1 al 6.
                        - **Objetivo (y):** Intenta adivinar qu√© pas√≥ en el mes 7.
                        
                        Luego, la ventana se mueve un mes a la derecha (meses 2 al 7) para predecir el mes 8, y as√≠ sucesivamente. De esta forma, transformamos una serie de tiempo en muchos ejemplos de entrenamiento.
                        """)
                        gr.Image("04_DOCUMENTACION/assets/sliding_window.png", label="Concepto de Ventana Deslizante", show_label=True)
                    
                    with gr.Column():
                        gr.Markdown("""
                        ### 2. Red Neuronal LSTM
                        
                        Usamos un tipo especial de cerebro digital llamado **LSTM (Long Short-Term Memory)**.
                        
                        A diferencia de una red normal, la LSTM tiene "memoria". Puede recordar patrones importantes de hace varios meses (como una temporada alta en diciembre) y olvidar datos irrelevantes.
                        
                        - **Celdas de Memoria:** Guardan informaci√≥n a largo plazo.
                        - **Puertas (Gates):** Deciden qu√© informaci√≥n entra, sale o se olvida.
                        
                        Es ideal para inventarios porque entiende que la demanda de hoy depende de la tendencia de los √∫ltimos meses.
                        """)
                        gr.Image("04_DOCUMENTACION/assets/lstm_architecture.png", label="Arquitectura LSTM Simplificada", show_label=True)
    return demo
